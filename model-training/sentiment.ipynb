{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "76dd1590-1dd7-4380-93b7-4491789eb84b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/admin/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 1\n",
    "%aimport sentiment_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff51efb6-9982-433e-b9b7-73a3ad88d354",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python:          3.10.11 (main, Apr  7 2023, 07:24:53) [Clang 14.0.0 (clang-1400.0.29.202)]\n",
      "PyTorch:         1.13.1\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import pandas as pd\n",
    "# import sklearn\n",
    "from tqdm import tqdm\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "print('python:'.ljust(16), sys.version.split('\\n')[0])\n",
    "# print('Scikit-learn:'.ljust(16), sklearn.__version__)\n",
    "print('PyTorch:'.ljust(16), torch.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b54d3a80-84d9-4a1a-996a-bc30784d09db",
   "metadata": {},
   "source": [
    "## Device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a5038b4-d83c-4bde-a230-0ca7538d5b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# Get cpu or gpu device for training\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {DEVICE} device')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1d1d08d-6b4f-4979-8ff5-b397c84c0383",
   "metadata": {},
   "source": [
    "## Hyperparameters & Constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6420d850-2109-4edc-937f-246d5d0312cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "# BATCH_SIZE = 64\n",
    "# EPOCHS = 15  # select from: 2**n - 1 = [1, 3, 7, 15, ...]\n",
    "# SCHEDULER_GAMMA = 0.7\n",
    "\n",
    "# Constants\n",
    "WORKING_PATH = './sentiment-data/'\n",
    "MODEL_PATH = '../app/models/'\n",
    "DATASET_NAME = 'tweet_eval'\n",
    "DATASET_CONF = 'sentiment'\n",
    "CLASSES = 3\n",
    "HUGGINGFACE_MODEL_NAME = 'cardiffnlp/twitter-roberta-base-sentiment-latest'\n",
    "\n",
    "# Actions\n",
    "# DO_LR_RANGE_TEST=False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a59c5513-1785-4de5-a58b-797d6ddd243e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Random state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3a433eb7-c8d0-44bf-a7d1-867166772870",
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 2147483647\n",
    "# random.seed(RANDOM_STATE)\n",
    "# np.random.seed(RANDOM_STATE)\n",
    "torch.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed(RANDOM_STATE)\n",
    "torch.cuda.manual_seed_all(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95a62e08-a57d-46f5-8d21-74df9a240575",
   "metadata": {},
   "source": [
    "## Load & show data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbc60f77-c4fe-459c-9a84-e2c674833aa9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset tweet_eval (/Users/admin/.cache/huggingface/datasets/tweet_eval/sentiment/1.1.0/12aee5282b8784f3e95459466db4cdf45c6bf49719c25cdb0743d71ed0410343)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "615d228cea53426e83a2b6aecefe1c7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 45615\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 12284\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['text', 'label'],\n",
       "        num_rows: 2000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = datasets.load_dataset(DATASET_NAME, DATASET_CONF)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a608d6b-b412-4319-8576-02575aa5d512",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': ['\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"',\n",
       "  '\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"',\n",
       "  'Sorry bout the stream last night I crashed out but will be on tonight for sure. Then back to Minecraft in pc tomorrow night.',\n",
       "  \"Chase Headley's RBI double in the 8th inning off David Price snapped a Yankees streak of 33 consecutive scoreless innings against Blue Jays\",\n",
       "  '@user Alciato: Bee will invest 150 million in January, another 200 in the Summer and plans to bring Messi by 2017\"'],\n",
       " 'label': [2, 1, 1, 1, 2]}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e96a266-7271-4ae2-816c-a5bdf86037b3",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3040eda8-5742-4c0d-b412-343ad7dd3fee",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "\" qt @user origin draft 7th book , remu lupin surviv battl hogwarts. #happybirthdayremuslupin \"\n",
      "\n",
      "\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"\n",
      "\" ben smith / smith ( concuss ) remain lineup thursday , curti #nhl #sj \"\n",
      "\n",
      "Sorry bout the stream last night I crashed out but will be on tonight for sure. Then back to Minecraft in pc tomorrow night.\n",
      "sorri bout stream last night crash tonight sure. back minecraft pc tomorrow night .\n",
      "\n",
      "Chase Headley's RBI double in the 8th inning off David Price snapped a Yankees streak of 33 consecutive scoreless innings against Blue Jays\n",
      "chase headley ' rbi doubl 8th inning david price snap yanke streak 33 consecut scoreless inning blue jay\n",
      "\n",
      "@user Alciato: Bee will invest 150 million in January, another 200 in the Summer and plans to bring Messi by 2017\"\n",
      "@user alciato : bee invest 150 million januari , anoth 200 summer plan bring messi 2017 \"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tokenizer = sentiment_utils.Tokenizer()\n",
    "\n",
    "for text in dataset['train']['text'][:5]:\n",
    "    print(text)\n",
    "    print(tokenizer(text, return_str=True))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb29efae-6858-4dd6-98d4-7f0824f53130",
   "metadata": {},
   "source": [
    "## Vectorization\n",
    "### Document vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5a363196-375b-4a06-a9c2-c648e0ce46f8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full size data shapes:\n",
      "BOW:         (45615, 50000) (2000, 50000) (12284, 50000)\n",
      "TFIDF:       (45615, 50000) (2000, 50000) (12284, 50000)\n",
      "Hashing BOW: (45615, 50000) (2000, 50000) (12284, 50000)\n",
      "\n",
      "SVD-truncated data shapes:\n",
      "BOW:         (45615, 100) (2000, 100) (12284, 100)\n",
      "TFIDF:       (45615, 100) (2000, 100) (12284, 100)\n",
      "Hashing BOW: (45615, 100) (2000, 100) (12284, 100)\n",
      "\n",
      "Explained variance for SVD:\n",
      "BOW:         51.53 %\n",
      "TFIDF:       16.50 %\n",
      "Hashing BOW: 41.75 %\n",
      "\n",
      "CPU times: user 27.7 ms, sys: 83.3 ms, total: 111 ms\n",
      "Wall time: 166 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "n_features = 50000\n",
    "svd_components = 100\n",
    "\n",
    "# Get vectorizers and data\n",
    "(\n",
    "    bow_vectorizer, x_train_bow, x_valid_bow, x_test_bow,\n",
    "    tfidf_vectorizer, x_train_tfidf, x_valid_tfidf, x_test_tfidf,\n",
    "    hashing_vectorizer, x_train_hashing, x_valid_hashing, x_test_hashing,\n",
    "    svd_bow_vectorizer, x_train_svd_bow, x_valid_svd_bow, x_test_svd_bow,\n",
    "    svd_tfidf_vectorizer, x_train_svd_tfidf, x_valid_svd_tfidf, x_test_svd_tfidf,\n",
    "    svd_hashing_vectorizer, x_train_svd_hashing, x_valid_svd_hashing, x_test_svd_hashing,\n",
    ") = sentiment_utils.get_bow_and_tfifd(\n",
    "    dataset,\n",
    "    n_features,\n",
    "    svd_components,\n",
    "    file=WORKING_PATH + 'bow_tfidf_' + str(n_features) + '_' + str(svd_components) + '.pickle',\n",
    "    saving=True,\n",
    ")\n",
    "\n",
    "# Print shapes\n",
    "print('Full size data shapes:')\n",
    "print('BOW:        ', x_train_bow.shape, x_valid_bow.shape, x_test_bow.shape)\n",
    "print('TFIDF:      ', x_train_tfidf.shape, x_valid_tfidf.shape, x_test_tfidf.shape)\n",
    "print('Hashing BOW:', x_train_hashing.shape, x_valid_hashing.shape, x_test_hashing.shape)\n",
    "print()\n",
    "print('SVD-truncated data shapes:')\n",
    "print('BOW:        ', x_train_svd_bow.shape, x_valid_svd_bow.shape, x_test_svd_bow.shape)\n",
    "print('TFIDF:      ', x_train_svd_tfidf.shape, x_valid_svd_tfidf.shape, x_test_svd_tfidf.shape)\n",
    "print('Hashing BOW:', x_train_svd_hashing.shape, x_valid_svd_hashing.shape, x_test_svd_hashing.shape)\n",
    "print()\n",
    "print('Explained variance for SVD:')\n",
    "print(f'BOW:         {(svd_bow_vectorizer.explained_variance_ratio_.sum() * 100):.2f} %')\n",
    "print(f'TFIDF:       {(svd_tfidf_vectorizer.explained_variance_ratio_.sum() * 100):.2f} %')\n",
    "print(f'Hashing BOW: {(svd_hashing_vectorizer.explained_variance_ratio_.sum() * 100):.2f} %')\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3252149e-5ec6-43c3-9407-036cb06ab72a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 0 0 ... 0 0 0]]\n",
      "(1, 50000)\n",
      "[[0.26755602 0.         0.         ... 0.         0.         0.        ]]\n",
      "(1, 50000)\n",
      "[[0. 0. 0. ... 0. 0. 0.]]\n",
      "(1, 50000)\n",
      "\n",
      "[ 0.30957865  1.00127087  0.11494237  0.87701774 -0.22821021 -0.21423857]\n",
      "(1, 100)\n",
      "[ 0.14219744  0.17554127  0.14005281 -0.0453262  -0.15248644 -0.09945275]\n",
      "(1, 100)\n",
      "[ 0.3206325   0.18681136  0.3500979  -0.13938562  0.38438379 -0.25106814]\n",
      "(1, 100)\n"
     ]
    }
   ],
   "source": [
    "text = ['Hello, world!']\n",
    "\n",
    "bow_output = bow_vectorizer.transform(text)\n",
    "tfidf_output = tfidf_vectorizer.transform(bow_output)\n",
    "hashing_output = hashing_vectorizer.transform(text)\n",
    "svd_bow_output = svd_bow_vectorizer.transform(bow_output)\n",
    "svd_tfidf_output = svd_tfidf_vectorizer.transform(tfidf_output)\n",
    "svd_hashing_output = svd_hashing_vectorizer.transform(hashing_output)\n",
    "\n",
    "print(bow_output.todense())\n",
    "print(bow_output.shape)\n",
    "print(tfidf_output.todense())\n",
    "print(tfidf_output.shape)\n",
    "print(hashing_output.todense())\n",
    "print(hashing_output.shape)\n",
    "print()\n",
    "print(svd_bow_output[0][:6])\n",
    "print(svd_bow_output.shape)\n",
    "print(svd_tfidf_output[0][:6])\n",
    "print(svd_tfidf_output.shape)\n",
    "print(svd_hashing_output[0][:6])\n",
    "print(svd_hashing_output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b51485a-e469-4dba-8e1f-e49f62abde40",
   "metadata": {},
   "source": [
    "### Arbitrary length vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ed5173ee-4af2-4dbb-87b8-e99ff4fd413e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"QT @user In the original draft of the 7th book, Remus Lupin survived the Battle of Hogwarts. #HappyBirthdayRemusLupin\"\n",
      "tensor([[    0,   113,  1864,   565,   787, 12105,    96,     5,  1461,  2479,\n",
      "             9,     5,   262,   212,  1040,     6,  8022,   687, 26110,   179,\n",
      "          5601,     5,  9846,     9, 42210,     4,   849, 21136, 44728,  1208,\n",
      "         31157,   687,   574,   658,   179,   113,    22,  1864,   565,   787,\n",
      "         12105,    96,     5,  1461,  2479,     9,     5,   262,   212,  1040,\n",
      "             6,  8022,   687, 26110,   179,  5601,     5,  9846,     9, 42210,\n",
      "             4,   849, 21136, 44728,  1208, 31157,   687,   574,   658,   179,\n",
      "           113,     2]])\n",
      "\n",
      "\"Ben Smith / Smith (concussion) remains out of the lineup Thursday, Curtis #NHL #SJ\"\n",
      "tensor([[    0,   113, 17521,  1259,  1589,  1259,    36,  3865, 33825,    43,\n",
      "          1189,    66,     9,     5,  4451,   296,     6, 11292,   849,   487,\n",
      "          8064,   849,   104,   863,   113,    22, 17521,  1259,  1589,  1259,\n",
      "            36,  3865, 33825,    43,  1189,    66,     9,     5,  4451,   296,\n",
      "             6, 11292,   849,   487,  8064,   849,   104,   863,   113,     2]])\n",
      "\n",
      "CPU times: user 205 ms, sys: 25.5 ms, total: 230 ms\n",
      "Wall time: 1.04 s\n"
     ]
    }
   ],
   "source": [
    "# Arbitrary length vectorizers (ALV)\n",
    "alv_pretrained = AutoTokenizer.from_pretrained(HUGGINGFACE_MODEL_NAME)\n",
    "\n",
    "for text in dataset['train']['text'][:2]:\n",
    "    print(text)\n",
    "    preprocessed_text = sentiment_utils.preprocess_text(text)\n",
    "    print(alv_pretrained(preprocessed_text, return_tensors='pt')['input_ids'])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c8e8288-5166-486e-853f-b0a6434af5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
